{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_ImportarDados.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celiaferreira/Covid19_RX/blob/master/1_ImportarDados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iV0IlaWFGX0G"
      },
      "source": [
        "### 1. Import data from multiple sources\n",
        "Efficient learning will allow us to distinguish cases of **COVID-19 pneumonia** from **other types of pneumonia** and from **normal situations**.\n",
        "\n",
        "There are repositories on the internet with the following situations, which we propose to distinguish within the scope of this project:\n",
        "\n",
        "*Covid-19\n",
        "*Viral pneumonia\n",
        "*Bacterial pneumonia\n",
        "* Situations without pathology (normal)\n",
        "\n",
        "In this project, data was collected from the following sources:\n",
        "\n",
        "* https://www.kaggle.com/darshan1504/covid19-detection-xray-dataset\n",
        "* https://www.kaggle.com/tawsifurrahman/covid19-radiography-database \n",
        "* https://github.com/ieee8023/covid-chestxray-dataset\n",
        "* https://www.kaggle.com/theroyakash/covid19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Abm1HtUPGRjl"
      },
      "source": [
        "### 1.1 Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "naGqhyNwGKKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "eabe7be7-2793-4961-9bcb-2970ade450fe"
      },
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm #barra de progreso`\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
        "#para redimencionar\n",
        "import sklearn\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from skimage.color import rgb2gray\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D, Flatten, Embedding, Dropout,BatchNormalization\n",
        "from keras.layers import MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D,concatenate,Input\n",
        "from keras.utils import to_categorical\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras import datasets, layers, models, optimizers\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from keras.applications import VGG19, InceptionResNetV2, ResNet50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SGme55BNGyqd"
      },
      "source": [
        "#### 1.2 Fontes online\n",
        "* Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oerk-QzTGRCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "3b956694-e1a3-4384-d50b-de719185d537"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"xxx\" #incluir username json kaggle\n",
        "os.environ['KAGGLE_KEY'] = \"xxxxxxx\" #incluir password json kaggle\n",
        "!kaggle datasets download -d darshan1504/covid19-detection-xray-dataset\n",
        "!kaggle datasets download -d tawsifurrahman/covid19-radiography-database\n",
        "!kaggle datasets download -d theroyakash/covid19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading covid19-detection-xray-dataset.zip to /content\n",
            " 94% 175M/186M [00:01<00:00, 116MB/s] \n",
            "100% 186M/186M [00:01<00:00, 116MB/s]\n",
            "Downloading covid19-radiography-database.zip to /content\n",
            " 99% 1.13G/1.15G [00:09<00:00, 123MB/s]\n",
            "100% 1.15G/1.15G [00:09<00:00, 133MB/s]\n",
            "Downloading covid19.zip to /content\n",
            " 94% 121M/128M [00:01<00:00, 119MB/s]\n",
            "100% 128M/128M [00:01<00:00, 124MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlTYRehaG2zc",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/covid19-detection-xray-dataset.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/covid19-detection-xray-dataset\")\n",
        "with zipfile.ZipFile(\"/content/covid19-radiography-database.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/covid19-radiography-database\")\n",
        "with zipfile.ZipFile(\"/content/covid19.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/covid19\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B5StlqG2HT20"
      },
      "source": [
        "* Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "otu90q4YHRj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "ac6e6949-6796-402b-dd50-ca9c8c99e562"
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 2467 (delta 79), reused 108 (delta 33), pack-reused 2283\u001b[K\n",
            "Receiving objects: 100% (2467/2467), 511.75 MiB | 42.10 MiB/s, done.\n",
            "Resolving deltas: 100% (1055/1055), done.\n",
            "Checking out files: 100% (564/564), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cIE68YZqHaAW"
      },
      "source": [
        "#### 1.3 Definição de repositórios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nF3rdTKwHVuA",
        "colab": {}
      },
      "source": [
        "#Fonte 1: https://www.kaggle.com/darshan1504/covid19-detection-xray-dataset\n",
        "PATH_train1 = '/content/covid19-detection-xray-dataset/NonAugmentedTrain/'\n",
        "PATH_test1 ='/content/covid19-detection-xray-dataset/ValData/'\n",
        "#/content/covid19-detection-xray-dataset/TrainData -> tem dados já aumentados, cópia de NonAugmentedTrain (não usado, porque faremos o nosso data augmentation)\n",
        "\n",
        "#Fonte 2: https://www.kaggle.com/tawsifurrahman/covid19-radiography-database \n",
        "PATH2='/content/covid19-radiography-database/COVID-19 Radiography Database/'\n",
        "\n",
        "#Fonte 3: https://github.com/ieee8023/covid-chestxray-dataset\n",
        "PATH3='/content/covid-chestxray-dataset/'\n",
        "\n",
        "#Fonte 4: https://www.kaggle.com/theroyakash/covid19 \n",
        "PATH4= '/content/covid19/xrays/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AIRt66tMHkLL"
      },
      "source": [
        "* Eliminar alguns ficheiros auxiliares que interferem com a importação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMqYn8H3HZOh",
        "colab": {}
      },
      "source": [
        "os.remove(\"/content/covid19-radiography-database/COVID-19 Radiography Database/COVID-19.metadata.xlsx\")\n",
        "os.remove(\"/content/covid19-radiography-database/COVID-19 Radiography Database/NORMAL.metadata.xlsx\")\n",
        "os.remove(\"/content/covid19-radiography-database/COVID-19 Radiography Database/Viral Pneumonia.matadata.xlsx\")\n",
        "os.remove(\"/content/covid19-radiography-database/COVID-19 Radiography Database/README.md.txt\")\n",
        "os.remove(\"/content/covid-chestxray-dataset/SCHEMA.md\")\n",
        "os.remove(\"/content/covid-chestxray-dataset/README.md\")\n",
        "os.remove(\"/content/covid-chestxray-dataset/metadata.csv\")\n",
        "os.remove(\"/content/covid-chestxray-dataset/requirements.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eca83g4yHrdm"
      },
      "source": [
        "#### 1.4 Importar dados\n",
        "A seguinte função auxilia na importação dos dados recolhidos dos vários repositórios, associando a respetiva label aos mesmos. Os dados são convertidos em arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_QBdVuEHjWw",
        "colab": {}
      },
      "source": [
        "def get_data(list):\n",
        "    X = []\n",
        "    y = []\n",
        "    label=-1\n",
        "    for folder in list:\n",
        "        for folderName in os.listdir(folder):\n",
        "            if not folderName.startswith('.'):\n",
        "                if folderName in ['COVID-19','covid','images']:\n",
        "                    label = 0\n",
        "                elif folderName in ['ViralPneumonia','Viral Pneumonia','viral neumonia']:\n",
        "                    label = 1\n",
        "                elif folderName in ['BacterialPneumonia','Bacterial Pneumonia']:\n",
        "                    label = 2               \n",
        "                elif folderName in ['NORMAL','Normal','normal']:\n",
        "                    label = 3\n",
        "                for image_filename in tqdm(os.listdir(folder + folderName)):\n",
        "                    img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
        "                    if img_file is not None:\n",
        "                        img_file = skimage.transform.resize(img_file, (200, 200, 3),mode='constant',\n",
        "                                                            anti_aliasing=True)\n",
        "                        img_file = rgb2gray(img_file)\n",
        "                        img_arr = np.asarray(img_file)\n",
        "                        X.append(img_arr)\n",
        "                        y.append(label)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)  \n",
        "    return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d0zticm2H3TB"
      },
      "source": [
        "Na primeira invocação (LOAD_FROM_IMAGES = True) é feito o load das imagens para os arrays, que são guardados. Nas invocações seguintes (LOAD_FROM_IMAGES = False) é apenas feito o load dos arrays guardados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5xxmZ_svHuip",
        "colab": {}
      },
      "source": [
        "list=[PATH_train1,PATH_test1,PATH2,PATH3,PATH4]\n",
        "\n",
        "LOAD_FROM_IMAGES = True\n",
        "#LOAD_FROM_IMAGES = False\n",
        "if LOAD_FROM_IMAGES:\n",
        "    #converter imagens em arrays\n",
        "    BD_X, BD_Y = get_data(list)\n",
        "\n",
        "   #gravar os arrays em ficheiros binários numpy (.npy)\n",
        "    np.save('x_BD.npy', BD_X)\n",
        "    np.save('y_BD.npy',BD_Y)\n",
        "    \n",
        "else:\n",
        "    #fazer o load dos arrays guardados\n",
        "    X_all = np.load('x_BD.npy')\n",
        "    y_all = np.load('y_BD.npy')  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
