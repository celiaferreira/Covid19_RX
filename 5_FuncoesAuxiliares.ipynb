{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_FuncoesAuxiliares.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celiaferreira/Covid19_RX/blob/master/5_FuncoesAuxiliares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn3U_cPRPGtn",
        "colab_type": "text"
      },
     "source": [
        "### 5. Auxiliary functions\n",
        "\n",
        "This section defines functions that will simplify the code in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuhD48oEUTuz",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Metrics\n",
        "\n",
        "We start by presenting metrics that will enrich the **report** of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yoRhBfTUkNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(label, confusion_matrix):\n",
        "    col = confusion_matrix[:, label]\n",
        "    return confusion_matrix[label, label] / col.sum()\n",
        "    \n",
        "def recall(label, confusion_matrix):\n",
        "    row = confusion_matrix[label, :]\n",
        "    return confusion_matrix[label, label] / row.sum()\n",
        "\n",
        "def precision_macro_average(confusion_matrix):\n",
        "    rows, columns = confusion_matrix.shape\n",
        "    sum_of_precisions = 0\n",
        "    for label in range(rows):\n",
        "        sum_of_precisions += precision(label, confusion_matrix)\n",
        "    return sum_of_precisions / rows\n",
        "\n",
        "def recall_macro_average(confusion_matrix):\n",
        "    rows, columns = confusion_matrix.shape\n",
        "    sum_of_recalls = 0\n",
        "    for label in range(columns):\n",
        "        sum_of_recalls += recall(label, confusion_matrix)\n",
        "    return sum_of_recalls / columns\n",
        "\n",
        "def accuracy(confusion_matrix):\n",
        "    diagonal_sum = confusion_matrix.trace()\n",
        "    sum_of_all_elements = confusion_matrix.sum()\n",
        "    return diagonal_sum / sum_of_all_elements "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GbRgCJJUnmB",
        "colab_type": "text"
      },
      "source": [
       "The following functions evaluate, for each model, the **confusion matrix**, **performance metrics** and **loss and accuracy plots**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4DaBLAXUnG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_metrics(model,history,X_test, y_test):\n",
        "   model.save('model.--{epoch:02d}-{val_accuracy:.2f}.h5')\n",
        "   filename = 'model.--{epoch:02d}-{val_accuracy:.2f}.sav'\n",
        "   joblib.dump(model, filename)\n",
        "\n",
        "   cm = confusion_matrix(y_test, np.argmax(model.predict(X_test),axis=1))\n",
        "   conf_mat=pd.DataFrame(cm)\n",
        "   conf_mat.index.name='Actual'\n",
        "   conf_mat.columns.name='Predicted'\n",
        "\n",
        "   print(conf_mat)\n",
        "   print('accuracy total:', accuracy(cm))\n",
        "   print('precision covid:', precision(0,cm))\n",
        "   print('recall covid:', recall(0,cm))\n",
        "   print('precision total:', precision_macro_average(cm))\n",
        "   print('recall total:', recall_macro_average(cm))\n",
        "\n",
        "   print(\"label precision recall\")\n",
        "   for label in range(len(unique_labels(y_test))):\n",
        "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n",
        "\n",
        "   results=model.evaluate(X_test, y_test)\n",
        "   print(results)\n",
        "\n",
        "   plt.figure(figsize=(12,4))\n",
        "   plt.subplot(1, 2, 1)\n",
        "   plt.plot(history.history['accuracy'])\n",
        "   plt.plot(history.history['val_accuracy'])\n",
        "   plt.title('Model accuracy')\n",
        "   plt.ylabel('Accuracy')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.subplot(1, 2, 2)\n",
        "   plt.plot(history.history['loss'])\n",
        "   plt.plot(history.history['val_loss'])\n",
        "   plt.title('Model loss')\n",
        "   plt.ylabel('Loss')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeWNY1Qeels3",
        "colab_type": "text"
      },
      "source": [
        "This version is required for transfer learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_hUiO6eeXQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_metrics_b(model,history,X_test, y_test):\n",
        "   model.save('model.--{epoch:02d}-{val_accuracy:.2f}.h5')\n",
        "   filename = 'model.--{epoch:02d}-{val_accuracy:.2f}.sav'\n",
        "   joblib.dump(model, filename)\n",
        "\n",
        "   cm = confusion_matrix(y_test, np.argmax(model.predict(X_test),axis=1))\n",
        "   conf_mat=pd.DataFrame(cm)\n",
        "   conf_mat.index.name='Actual'\n",
        "   conf_mat.columns.name='Predicted'\n",
        "\n",
        "   print(conf_mat)\n",
        "   print('accuracy total:', accuracy(cm))\n",
        "   print('precision covid:', precision(0,cm))\n",
        "   print('recall covid:', recall(0,cm))\n",
        "   print('precision total:', precision_macro_average(cm))\n",
        "   print('recall total:', recall_macro_average(cm))\n",
        "\n",
        "   print(\"label precision recall\")\n",
        "   for label in range(len(unique_labels(y_test))):\n",
        "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n",
        "\n",
        "   results=model.evaluate(X_test, y_test)\n",
        "   print(results)\n",
        "\n",
        "   plt.figure(figsize=(12,4))\n",
        "   plt.subplot(1, 2, 1)\n",
        "   plt.plot(history.history['acc'])\n",
        "   plt.plot(history.history['val_acc'])\n",
        "   plt.title('Model accuracy')\n",
        "   plt.ylabel('Accuracy')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.subplot(1, 2, 2)\n",
        "   plt.plot(history.history['loss'])\n",
        "   plt.plot(history.history['val_loss'])\n",
        "   plt.title('Model loss')\n",
        "   plt.ylabel('Loss')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMERm8zfiHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_metrics2(model,history,X_test, y_test):\n",
        "   model.save('model.--{epoch:02d}-{val_accuracy:.2f}.h5')\n",
        "   filename = 'model.--{epoch:02d}-{val_accuracy:.2f}.sav'\n",
        "   joblib.dump(model, filename)\n",
        "\n",
        "   cm = confusion_matrix(y_test, np.argmax(model.predict(X_test),axis=1))\n",
        "   conf_mat=pd.DataFrame(cm)\n",
        "   conf_mat.index.name='Actual'\n",
        "   conf_mat.columns.name='Predicted'\n",
        "\n",
        "   print(conf_mat)\n",
        "   print('accuracy total:', accuracy(cm))\n",
        "   print('precision covid:', precision(0,cm))\n",
        "   print('recall covid:', recall(0,cm))\n",
        "   print('precision total:', precision_macro_average(cm))\n",
        "   print('recall total:', recall_macro_average(cm))\n",
        "\n",
        "   print(\"label precision recall\")\n",
        "   for label in range(len(unique_labels(y_test))):\n",
        "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n",
        "\n",
        "   results=model.evaluate(X_test, y_test)\n",
        "   print(results)\n",
        "\n",
        "   plt.figure(figsize=(12,4))\n",
        "   plt.subplot(1, 2, 1)\n",
        "   plt.plot(history.history['accuracy'])\n",
        "   plt.title('Model accuracy')\n",
        "   plt.ylabel('Accuracy')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.subplot(1, 2, 2)\n",
        "   plt.plot(history.history['loss'])\n",
        "   plt.title('Model loss')\n",
        "   plt.ylabel('Loss')\n",
        "   plt.xlabel('Epoch')\n",
        "   plt.legend(['Train', 'Test'], loc='upper left')\n",
        "   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5FD1-gUx7M",
        "colab_type": "text"
      },
      "source": [
        "### 5.2 Layer view\n",
        "\n",
        "Once a model is specified, the following function displays details about its **layers**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWmLR2RPUxcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot camadas convolucionais e fully connected\n",
        "\n",
        "def camadas(model):\n",
        "  print('Camadas convolucionais:')\n",
        "  # summarize filter shapes\n",
        "  for layer in model.layers:\n",
        "  #check for convolutional layer\n",
        "      if 'conv' not in layer.name:\n",
        "          continue   \n",
        "  # get filter weights\n",
        "      else:\n",
        "          filters, biases = layer.get_weights()\n",
        "          print(layer.name, filters.shape)\n",
        "\n",
        "\n",
        "  print('Camadas fully connected:')\n",
        "  # summarize layers shapes\n",
        "  for layer in model.layers:\n",
        "  #check for fully conection layer\n",
        "      if 'dense' not in layer.name:\n",
        "          continue \n",
        "      else:\n",
        "          filters, biases = layer.get_weights()\n",
        "          print(layer.name, filters.shape)\n",
        "\n",
        "  print('imagens saída de Capas Convolucionais:')\n",
        "  plt.figure(figsize=(20,20))\n",
        "  # retrieve weights from the second hidden layer\n",
        "  filters, biases = model.layers[0].get_weights()\n",
        "  # normalize filter values to 0-1 so we can visualize them\n",
        "  f_min, f_max = filters.min(), filters.max()\n",
        "  filters = (filters - f_min) / (f_max - f_min)\n",
        "  # plot first few filters\n",
        "  n_filters, ix = 6, 1\n",
        "  for i in range(n_filters):\n",
        "  # get the filter\n",
        "      f = filters[:, :, :, i]\n",
        "      # plot each channel separately\n",
        "      for j in range(1):\n",
        "          # specify subplot and turn of axis\n",
        "          ax = plt.subplot(n_filters, 3, ix )\n",
        "          ax.set_xticks([])\n",
        "          ax.set_yticks([])\n",
        "          # plot filter channel in grayscale\n",
        "          plt.imshow(f[:, :, j],cmap='gray')\n",
        "          ix += 1\n",
        "  # show the figure\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
